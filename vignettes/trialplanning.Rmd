---
title: 'simIDM: Power and Type I Error Calculations'
author: "Alexandra Erdmann"
date: "11/14/2022"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: |
  %\VignetteIndexEntry{simIDM: Power and Type I Error Calculations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

This vignette demonstrates how to use `simIDM` for trial design planning with a simple example. We will show how to estimate type I errors and statistical power from simulations to optimize study design (see @erdmann2023 for more details).
Jointly modeling the endpoints PFS and OS with the illness-death model has two major advantages:
- we properly account for the correlation between PFS and OS
- the strong assumption of proportional hazards is not required
OS is defined as the time to reach the absorbing state death, and PFS is defined as the time to reach the absorbing state `death` or the intermediate state `progression`, whichever occurs first.
Figure 1 shows the multistate model with the corresponding transition hazards.
In the vignette, we show how to estimate type I errors and statistical power from simulations and give an idea on how this can be used to plan complex study trials.

```{r, echo=FALSE,  fig.cap = " Figure 1 - Multistate model with indermediate state progession and absorbing state death", fig.height = 5, fig.width = 8, out.width = "60%"}
library(prodlim)
plotIllnessDeathModel(
  style = 1, box1.label = "0: initial state", box2.label = "1: progression",
  box3.label = "2: death", arrowLabelSymbol = "h"
)
```
## Scenario -  PFS and OS as Co-primary Endpoints

We consider the following study design:

- PFS and OS as co-primary endpoints with one final analysis each
- treatment vs. control group, 1:1 randomization ratio  (but note that in principle any randomization ratio can be implemented)
- global significance level of 5 \%
- the standard log-rank test is used to detect a significant difference between the groups
- statistical power to detect a difference between the groups should be 80 \% for each endpoint
- 5 \% drop-out rate within 12 time units
- accrual of 100 patients per time unit


Using the multistate model approach implies that trial planning is based on assumptions on the three transition hazards in each arm, i.e. six hazards in total (which induces assumptions on the endpoints PFS and OS).
In our example scenario, we assume constant transition hazards and a small effect of the treatment on hazards from the initial state to death.
Median time until a PFS event is 0.99 time units in the control arm and 1.44 time units in the treatment arm.
Median time until an OS event is 1.94 time units in the control group and 2.29 time units in the treatment group.
Figure 2 shows the transition hazards, survival functions, hazard functions and hazard ratios for both endpoints.

![Figure 2 - Transition hazards, survival functions, hazard functions and hazard ratios for our scenario.](scenario.png)

The transition hazards are specified as follows:
```{r}
library(simIDM)
transitionTrt <- exponential_transition(h01 = 0.2, h02 = 0.28, h12 = 0.4)
transitionPl <- exponential_transition(h01 = 0.4, h02 = 0.3, h12 = 0.5)

transitionList <- list(transitionPl, transitionTrt)
```

The package provides functions that return the values of the PFS or OS survival functions for given transition hazards (Constant, Weibull or Piecewise Constant) and time points.
```{r}
timepoints <- c(0, 0.1, 0.3, 0.7, 1, 5)
# Survival function for Constant transition hazards:
ExpSurvOS(timepoints, h01 = 0.2, h02 = 0.4, h12 = 0.1)
# Survival function for Weibull transition hazards:
WeibSurvOS(timepoints, h01 = 0.2, h02 = 0.5, h12 = 2.1, p01 = 1.2, p02 = 0.9, p12 = 1)
# Survival function for Piecewise Constant transition hazards:
PWCsurvOS(timepoints,
  h01 = c(0.3, 0.5), h02 = c(0.5, 0.8), h12 = c(0.7, 1),
  pw01 = c(0, 4), pw02 = c(0, 8), pw12 = c(0, 3)
)
```
There are also functions for PFS survival functions available.

For PFS, the hazard ratio under $H_0$ is known by specification (0.6857); for OS, an averaged HR can be calculated using `avgHRExpOS` (note that this requires constant transition hazards):

```{r}
avgHRExpOS(transitionByArm = transitionList, alpha = 0.5, upper = 1000)
```

In our example, we get an average OS HR of `r round(avgHRExpOS(transitionByArm = transitionList, alpha = 0.5, upper = 1000), 3)`.

## Type I Error - Simulation Under $H_0$

The type I error can be estimated empirically by simulating clinical trials under $H_0$. To achieve this, we set the transition hazards of the treatment group to match those of the control group.
Then, we use `getClinicalTrials()` to generate a large number of simulated trials. We will use 100 iterations here, for applications however a higher number (e.g. 10,000) is recommended.

```{r}
transitionListNull <- list(transitionPl, transitionPl)
nRep <- 100
simNull <- getClinicalTrials(
  nRep = nRep, nPat = c(800, 800), seed = 1238, datType = "1rowPatient",
  transitionByArm = transitionListNull,
  dropout = list(rate = 0.05, time = 12), accrual = list(param = "intensity", value = 100)
)
```

Using the simulation, we can now identify critical log-rank test values for both PFS and OS to maintain a 5\% global significance level. Initially, we allocate critical values so that the two-sided log-rank test has a 4\% significance level for the OS endpoint and 1% for the PFS endpoint, effectively splitting the global significance level. This method is widely used in trials with co-primary endpoints.

```{r}
alphaOS <- 0.04
alphaPFS <- 0.01
criticalOS <- abs(qnorm(alphaOS / 2))
criticalPFS <- abs(qnorm(alphaPFS / 2))
```

With the Schoenfeld approximation, preliminary sample sizes can be computed to get an idea of how many events are needed to achieve 80 \% power. Using these critical values and required number of events for PFS and OS, we can now determine the global type I error empirically by counting the number of trials simulated under $H_0$ with significant log-rank tests.
The empirical type I error for each endpoint is calculated as the proportion of trials with significant log-rank tests, while the global Type I error is the proportion of trials where at least one of PFS or OS with a significant log-rank test. This can be done using `empSignificant`:

```{r}
empSignificant(simTrials = simNull,
         criticalPFS = criticalPFS,
         criticalOS = criticalOS,
         eventNumPFS = 329,
         eventNumOS = 660)
```
In this example, the empirical type I error rate is 3\%.
If the empirical type-I error is lower or higher than 5\%, the critical values used for the log-rank test can be adjusted until a significance level close to 5\% is obtained. This could be done, for example, in the following way:

```{r eval=FALSE}
while (empGlobalAlpha < 0.049) {
  criticalPFS <- criticalPFS - 0.01
  criticalOS <- criticalOS - 0.01

# empirical global significance level
empGlobalAlpha <- empSignificant(simTrials = simNull,
                                 criticalPFS = criticalPFS,
                                 criticalOS = criticalOS,
                                 eventNumPFS = 329,
                                 eventNumOS = 660)[[3]]
}
```

## Sample size and power calculation - simulation under $H_1$

Next, we simulate a large number of trials under $H_1$ to compute the empirical power:

```{r}
simH1 <- getClinicalTrials(
  nRep = nRep, nPat = c(800, 800), seed = 1238, datType = "1rowPatient",
  transitionByArm = transitionList,
  dropout = list(rate = 0.05, time = 12), accrual = list(param = "intensity", value = 100)
)
```

The empirical power for each endpoint is the proportion of simulated trials with significant log-rank tests under $H_1$. The multistate model approach allows us to easily estimate further interesting metrics, such as joint power, i.e. the probability that both endpoints in a trial are significant, if each endpoint is analyzed at its planned time-point.

```{r}
empSignificant(simTrials = simH1,
         criticalPFS = criticalPFS,
         criticalOS = criticalOS,
         eventNumPFS = 329,
         eventNumOS = 660)
```
In this example, for the endpoint OS, the number of events has to be increased to obtain a power of 80 \%.

It is also possible to derive the median time at which a certain number of events are expected to occur and how many events of the second endpoint have occurred at that time on average.

```{r}
# median time point for 329 PFS events to have occurred:
timePointsPFS <- lapply(simH1,getTimePoint,
  eventNum = 329, typeEvent = "PFS",
  byArm = FALSE
)
median(unlist(timePointsPFS))

# median time point for 684 OS events to have occurred:
timePointsOS <- lapply(simH1, getTimePoint,
  eventNum = 684, typeEvent = "OS",
  byArm = FALSE
)
median(unlist(timePointsOS))

# mean number of PFS events at time of OS analysis
eventsPFS <- lapply(
  seq_along(timePointsPFS),
  function(t) {
    return(sum(simH1[[t]]$OSevent[(simH1[[t]]$OStime + simH1[[t]]$recruitTime)
    <= timePointsPFS[[t]]]))
  }
)
mean(unlist(eventsPFS))

# mean number of OS events at time of PFS analysis
eventsOS <- lapply(
  seq_along(timePointsOS),
  function(t) {
    return(sum(simH1[[t]]$PFSevent[(simH1[[t]]$PFStime + simH1[[t]]$recruitTime)
    <= timePointsOS[[t]]]))
  }
)
mean(unlist(eventsOS))

```


## References
